import os, json, numpy as np, streamlit as st, faiss
from openai import OpenAI

st.set_page_config(page_title="Family Rules Bot", page_icon="ğŸ‘ª")
st.title("å®¶æ—ã®ãƒ«ãƒ¼ãƒ«ã®ç¢ºèªã‚¢ãƒ—ãƒª")

# --- èªè¨¼ ---
my_api_key = (st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY")) or "").strip()
if not my_api_key:
    st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã¯ .streamlit/secrets.tomlã€Cloud ã¯ Settingsâ†’Secrets ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")
    st.stop()
client = OpenAI(api_key=my_api_key)

# --- ãƒ‘ã‚¹ãƒ»ãƒ¢ãƒ‡ãƒ« ---
base = os.path.dirname(os.path.abspath(__file__))
data_dir = os.path.join(base, "data")
vs_dir   = os.path.join(base, "vectorstore")
os.makedirs(data_dir, exist_ok=True)
os.makedirs(vs_dir,   exist_ok=True)

rules_path = os.path.join(data_dir, "rules.txt")
index_path = os.path.join(vs_dir,   "faiss.index")
meta_path  = os.path.join(vs_dir,   "meta.json")
embed_model = "text-embedding-3-small"

# --- rules.txt èª­ã¿è¾¼ã¿ï¼ˆå…ˆé ­ãŒã€Œãƒ«ãƒ¼ãƒ«ï¼šã€ã®è¡Œã ã‘æ¡ç”¨ï¼‰ ---
rules_texts = []
if os.path.exists(rules_path):
    with open(rules_path, "r", encoding="utf-8") as f:
        for ln in f:
            s = ln.strip()
            if s and not s.startswith("#") and s.startswith("ãƒ«ãƒ¼ãƒ«ï¼š"):
                content = s[len("ãƒ«ãƒ¼ãƒ«ï¼š"):].strip()
                if content:
                    rules_texts.append(content)
else:
    st.warning("data/rules.txt ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¾‹ï¼‰ãƒ«ãƒ¼ãƒ«ï¼š ãŠã‚„ã¤ã¯åˆå¾Œ3æ™‚ã¾ã§ã ã‚ˆã€‚")

# --- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼šã‚ã‚Œã°èª­ã‚€ï¼ãªã‘ã‚Œã°ä½œã‚‹ ---
rules, index = [], None
if os.path.exists(index_path) and os.path.exists(meta_path):
    try:
        meta = json.load(open(meta_path, "r", encoding="utf-8"))
        if meta.get("model") == embed_model:
            index = faiss.read_index(index_path)
            rules = list(meta.get("rules", []))   # ã€Œãƒ«ãƒ¼ãƒ«ï¼šã€æŠœãæœ¬æ–‡ã®é…åˆ—
            st.caption("FAISS: loaded existing index")
    except Exception:
        index = None

if index is None:
    rules = list(rules_texts)
    if rules:
        emb = client.embeddings.create(model=embed_model, input=rules)
        X = np.array([d.embedding for d in emb.data], dtype="float32")
        X /= (np.linalg.norm(X, axis=1, keepdims=True) + 1e-9)   # ã‚³ã‚µã‚¤ãƒ³ç”¨ã«æ­£è¦åŒ–
        d = X.shape[1]
        index = faiss.IndexFlatIP(d)                              # å†…ç©ï¼ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        index.add(X)
        faiss.write_index(index, index_path)
        json.dump({"model": embed_model, "rules": rules}, open(meta_path, "w", encoding="utf-8"), ensure_ascii=False)
        st.caption("FAISS: built & saved")

# --- è³ªå• â†’ åˆ†é¡ â†’ï¼ˆå¿…è¦ãªã‚‰ï¼‰RAG â†’ å¿œç­” ---
msg = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ã­ï¼ˆä¾‹ï¼šãŠã‚„ã¤ã¯ã„ã¤ï¼Ÿï¼‰")
if msg:
    with st.chat_message("user"):
        st.write(msg)

    # â‘  å®¶åº­ã®ãƒ«ãƒ¼ãƒ«ã«é–¢ã™ã‚‹è³ªå•ï¼Ÿï¼ˆYES/NOã ã‘å‡ºã™ï¼‰
    cls_system = (
        "ã‚ãªãŸã¯çŸ­ã„åˆ¤å®šã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "å…¥åŠ›ãŒã€å®¶åº­å†…ã®ãƒ«ãƒ¼ãƒ«ï¼ˆã—ã¦ã„ã„/ã ã‚ã€ä½•æ™‚ã¾ã§ã€ã©ã‚Œãã‚‰ã„ç­‰ï¼‰ã€ã«é–¢ã™ã‚‹è³ªå•ãªã‚‰ YESã€"
        "ãã†ã§ãªã‘ã‚Œã° NOã€‚å‡ºåŠ›ã¯å¿…ãš YES ã‹ NO ã®ã¿ã€‚"
    )
    cls = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0,
        messages=[{"role":"system","content":cls_system},{"role":"user","content": msg}],
    ).choices[0].message.content.strip().upper()

    if cls != "YES":
        # ãƒ«ãƒ¼ãƒ«è³ªå•ã§ã¯ãªã„ â†’ ä¸€èˆ¬çš„ãªãƒãƒ£ãƒƒãƒˆå¿œç­”
        gen = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.6,
            messages=[
                {"role":"system","content":"ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å­ã©ã‚‚ã«ã‚‚åˆ†ã‹ã‚‹è¡¨ç¾ã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"},
                {"role":"user","content": msg},
            ],
        )
        with st.chat_message("assistant"):
            st.write(gen.choices[0].message.content)
        st.caption("(general chat)")
    else:
        # ãƒ«ãƒ¼ãƒ«è³ªå• â†’ RAG å¯å¦ã‚’åˆ¤å®š
        use_fallback = False
        fb_reason = ""
        best_i, best_sim = -1, 0.0

        if not rules or index is None:
            use_fallback = True
            fb_reason = "no rules/index"
        else:
            # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆTop1ï¼‰
            q = client.embeddings.create(model=embed_model, input=[msg]).data[0].embedding
            q = np.array(q, dtype="float32")[None, :]
            q /= (np.linalg.norm(q, axis=1, keepdims=True) + 1e-9)
            D, I = index.search(q, 1)
            best_sim, best_i = float(D[0][0]), int(I[0][0])
            TH = 0.65
            if best_sim < TH:
                use_fallback = True
                fb_reason = f"no match, sim: {best_sim:.2f}"

        if use_fallback:
            # RAGä¸å¯ or è©²å½“ãƒ«ãƒ¼ãƒ«ãªã— â†’ ä¸€èˆ¬çš„ãªç›®å®‰ã§å›ç­”ï¼ˆå…±é€šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            system = (
                "ã‚ãªãŸã¯å®¶åº­å†…ãƒ«ãƒ¼ãƒ«ã‚’ã‚„ã•ã—ãèª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
                "æ–­å®šã¯é¿ã‘ã€å­ã©ã‚‚ã«ã‚‚åˆ†ã‹ã‚‹çŸ­ã„æ–‡ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
                "æœ€å¾Œã«ã€ãŠã†ã¡ã®äººã«ç¢ºèªã—ã¦ã­ã€ã¨æ·»ãˆã¦ãã ã•ã„ã€‚"
            )
            prompt = f"è³ªå•: {msg}\n\nä¸€èˆ¬çš„ãªç›®å®‰ã‚’1ã€œ2æ–‡ã§ä¼ãˆã¦ãã ã•ã„ã€‚"
            res = client.chat.completions.create(
                model="gpt-4o-mini",
                temperature=0.4,
                messages=[{"role":"system","content":system},{"role":"user","content":prompt}],
            )
            with st.chat_message("assistant"):
                st.write(res.choices[0].message.content)
                if fb_reason:
                    st.caption(f"({fb_reason})")
        else:
            # è©²å½“ãƒ«ãƒ¼ãƒ«ã‚ã‚Š â†’ ãƒ«ãƒ¼ãƒ«ã‚’æ ¹æ‹ ã«å›ç­”
            rule_text = rules[best_i]
            system = "ã‚ãªãŸã¯å®¶åº­å†…ãƒ«ãƒ¼ãƒ«ã‚’ã‚„ã•ã—ãèª¬æ˜ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å­ä¾›ã«ã‚‚ã‚ã‹ã‚‹çŸ­ã„æ–‡ã§ç­”ãˆã¦ãã ã•ã„ã€‚"
            context = f"å®¶åº­ã®ãƒ«ãƒ¼ãƒ«ï¼ˆè©²å½“ï¼‰:\n- {rule_text}"
            res = client.chat.completions.create(
                model="gpt-4o-mini",
                temperature=0.2,
                messages=[
                    {"role":"system","content": system},
                    {"role":"user", "content": f"{context}\n\nè³ªå•: {msg}\n\nä¸Šã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦ã€å­ã©ã‚‚ã«ã‚‚åˆ†ã‹ã‚‹è¨€è‘‰ã§1ã€œ2æ–‡ã§ç­”ãˆã¦ã€‚"},
                ],
            )
            with st.chat_message("assistant"):
                st.write(res.choices[0].message.content)
                st.caption(f"(match: {rule_text[:20]}â€¦ , sim: {best_sim:.2f})")


st.caption("Powered by OpenAI (RAG: FAISS + text-embedding-3-small)")